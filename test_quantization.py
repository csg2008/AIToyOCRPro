#!/usr/bin/env python3
"""
å‰ªæåŠŸèƒ½æµ‹è¯•è„šæœ¬
"""
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import torch
import torch.nn as nn
from main import parse_args, prepare_model, setup_device
from quantization import PruningConfig, PruningManager, create_pruning_config

def test_pruning_basic():
    """æµ‹è¯•å‰ªæçš„åŸºæœ¬åŠŸèƒ½"""
    print("ğŸ” å¼€å§‹æµ‹è¯•å‰ªæåŸºæœ¬åŠŸèƒ½...")

    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parse_args()
    args.enable_pruning = True
    args.pruning_strategy = 'l1_unstructured'
    args.pruning_ratio = 0.3
    args.pruning_epoch = 5
    args.finetune_epochs = 3

    # è®¾ç½®è®¾å¤‡
    device = setup_device('cpu')
    print(f"âœ… è®¾å¤‡è®¾ç½®å®Œæˆ: {device}")

    # å‡†å¤‡æ¨¡å‹
    checkpoint = ''  # ä¸ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹
    model, ckpt = prepare_model(args, device, checkpoint)
    print(f"âœ… æ¨¡å‹åˆ›å»ºå®Œæˆ")

    # åˆ›å»ºå‰ªæé…ç½®
    pruning_config = create_pruning_config(args)
    print(f"âœ… å‰ªæé…ç½®åˆ›å»ºå®Œæˆ: {pruning_config.to_dict()}")

    # åˆå§‹åŒ–å‰ªæç®¡ç†å™¨
    pruning_manager = PruningManager(pruning_config, model)
    print(f"âœ… å‰ªæç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")

    # æµ‹è¯•å‰ªææ—¶é—´æ£€æŸ¥
    epoch = 0
    is_pruning_time = pruning_manager.is_pruning_time(epoch)
    print(f"âœ… å‰ªææ—¶é—´æ£€æŸ¥: epoch={epoch}, is_pruning_time={is_pruning_time}")

    epoch = args.pruning_epoch
    is_pruning_time = pruning_manager.is_pruning_time(epoch)
    print(f"âœ… å‰ªææ—¶é—´æ£€æŸ¥: epoch={epoch}, is_pruning_time={is_pruning_time}")

    # æµ‹è¯•å¾®è°ƒæ—¶é—´æ£€æŸ¥
    is_finetuning = pruning_manager.is_finetuning_time(epoch)
    print(f"âœ… å¾®è°ƒæ—¶é—´æ£€æŸ¥: epoch={epoch}, is_finetuning={is_finetuning}")

    epoch = args.pruning_epoch + 1
    is_finetuning = pruning_manager.is_finetuning_time(epoch)
    print(f"âœ… å¾®è°ƒæ—¶é—´æ£€æŸ¥: epoch={epoch}, is_finetuning={is_finetuning}")

    # æµ‹è¯•å­¦ä¹ ç‡ä¹˜æ•°
    lr_multiplier = pruning_manager.get_finetune_lr_multiplier(epoch)
    print(f"âœ… å­¦ä¹ ç‡ä¹˜æ•°: epoch={epoch}, lr_multiplier={lr_multiplier}")

    # æµ‹è¯•æ¨¡å‹ä¿¡æ¯è·å–
    prune_info = pruning_manager.get_pruned_model_info()
    print(f"âœ… æ¨¡å‹ä¿¡æ¯è·å–: {prune_info}")

    print("ğŸ‰ å‰ªæåŸºæœ¬åŠŸèƒ½æµ‹è¯•å®Œæˆï¼")
    return True

def test_pruning_application():
    """æµ‹è¯•å‰ªæåº”ç”¨"""
    print("\nğŸ” å¼€å§‹æµ‹è¯•å‰ªæåº”ç”¨...")

    # åˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•æ¨¡å‹
    class TestModel(nn.Module):
        def __init__(self):
            super().__init__()
            self.backbone = nn.Sequential(
                nn.Conv2d(3, 16, kernel_size=3, padding=1, stride=2),
                nn.ReLU(),
                nn.Conv2d(16, 32, kernel_size=3, padding=1, stride=2),
                nn.ReLU()
            )
            # è®¡ç®—neckå±‚çš„è¾“å…¥ç»´åº¦ï¼š32x32 -> 16x16 -> 8x8
            self.neck = nn.Linear(32 * 8 * 8, 128)
            self.decoder = nn.Linear(128, 10)

        def forward(self, x):
            x = self.backbone(x)
            x = x.view(x.size(0), -1)
            x = self.neck(x)
            x = self.decoder(x)
            return x

    # åˆ›å»ºæ¨¡å‹
    model = TestModel()
    print(f"âœ… æµ‹è¯•æ¨¡å‹åˆ›å»ºå®Œæˆ")

    # åˆ›å»ºå‰ªæé…ç½®
    pruning_config = PruningConfig({
        'enabled': True,
        'pruning_strategy': 'l1_unstructured',
        'pruning_ratio': 0.5,
        'pruning_layers': ['backbone', 'neck', 'decoder'],
        'pruning_epoch': 0,
        'finetune_epochs': 3
    })
    print(f"âœ… å‰ªæé…ç½®åˆ›å»ºå®Œæˆ")

    # åˆå§‹åŒ–å‰ªæç®¡ç†å™¨
    pruning_manager = PruningManager(pruning_config, model)
    print(f"âœ… å‰ªæç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")

    # æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹ä¸­çš„å‰ªæåº”ç”¨
    current_acc = 0.95
    best_acc = 0.96
    pruning_applied = pruning_manager.apply_pruning(0, current_acc, best_acc)
    print(f"âœ… å‰ªæåº”ç”¨: {pruning_applied}")

    # æ£€æŸ¥å‰ªææ¯”ä¾‹
    pruning_ratio = pruning_manager.calculate_pruning_ratio()
    print(f"âœ… å‰ªææ¯”ä¾‹: {pruning_ratio:.2%}")

    # è·å–å‰ªæä¿¡æ¯
    prune_info = pruning_manager.get_pruned_model_info()
    print(f"âœ… å‰ªæä¿¡æ¯: {prune_info}")

    # æ°¸ä¹…åŒ–å‰ªæ
    pruning_manager.remove_pruning()
    print(f"âœ… å‰ªææ°¸ä¹…åŒ–å®Œæˆ")

    # æµ‹è¯•æ¨¡å‹æ˜¯å¦è¿˜èƒ½æ­£å¸¸å·¥ä½œ
    dummy_input = torch.randn(1, 3, 32, 32)
    output = model(dummy_input)
    print(f"âœ… æ¨¡å‹æ¨ç†æµ‹è¯•: output.shape={output.shape}")

    print("ğŸ‰ å‰ªæåº”ç”¨æµ‹è¯•å®Œæˆï¼")
    return True

if __name__ == "__main__":
    print("ğŸš€ å‰ªæåŠŸèƒ½æµ‹è¯•")
    print("=" * 50)

    try:
        # è¿è¡ŒåŸºæœ¬åŠŸèƒ½æµ‹è¯•
        test_pruning_basic()

        # è¿è¡Œå‰ªæåº”ç”¨æµ‹è¯•
        test_pruning_application()

        print("\n" + "=" * 50)
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å‰ªæåŠŸèƒ½æ­£å¸¸å·¥ä½œã€‚")
        sys.exit(0)
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
